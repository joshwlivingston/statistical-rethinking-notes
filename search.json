[
  {
    "objectID": "homework/index.html",
    "href": "homework/index.html",
    "title": "Homework Solutions",
    "section": "",
    "text": "This section contains my solutions to the course homework assignments.\nHomework solutions will be added as assignments are completed.",
    "crumbs": [
      "Homework",
      "Homework Solutions"
    ]
  },
  {
    "objectID": "course/index.html",
    "href": "course/index.html",
    "title": "Course Notes",
    "section": "",
    "text": "This section contains notes from the pre-recorded lectures and slides.\nCourse content will be added as lectures are completed.",
    "crumbs": [
      "Course",
      "Course Notes"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "License",
    "section": "",
    "text": "The original prose, notes, and summaries created by Josh Livingston are licensed under CC0 1.0 Universal. All original source code and code examples are licensed under the MIT License.\n\n\nThis project is an independent, unofficial study resource based on the book and course “Statistical Rethinking” by Richard McElreath.\n\nThe intellectual framework, terminology, pedagogical structure, and original examples belong to Richard McElreath.\nThis project is intended to complement, not replace, the original text. Users are strongly encouraged to purchase the book at https://xcelab.net/rm/."
  },
  {
    "objectID": "LICENSE.html#attribution-notice",
    "href": "LICENSE.html#attribution-notice",
    "title": "License",
    "section": "",
    "text": "This project is an independent, unofficial study resource based on the book and course “Statistical Rethinking” by Richard McElreath.\n\nThe intellectual framework, terminology, pedagogical structure, and original examples belong to Richard McElreath.\nThis project is intended to complement, not replace, the original text. Users are strongly encouraged to purchase the book at https://xcelab.net/rm/."
  },
  {
    "objectID": "book/02_small-worlds-and-large-worlds.html",
    "href": "book/02_small-worlds-and-large-worlds.html",
    "title": "Chapter 2: Small Worlds and Large Worlds",
    "section": "",
    "text": "Statistical modeling exists dualistically, in a small world (contained by the model’s inherent logic) and a big world (the context in which the model will live).\nIn the small world, it is important to make sure the model is valid, consistent, and well-behaved.\nThe large world is the broader context in which the finalized model will exist. It is important to note that the statistical model always underrepresents the full context of the large world. Out of sample data emerge, and a model’s logical inconsistencies can surface.\nAdapting to the large world is a straightforward process, for nature. For Bayesian models, the process is much more complex. It is difficult to beat natural heuristics once a model identifies what to look for.\nChapter 2 focuses on the small world.",
    "crumbs": [
      "Book Notes",
      "Chapter 2: Small Worlds and Large Worlds"
    ]
  },
  {
    "objectID": "LICENSE-CC0.html",
    "href": "LICENSE-CC0.html",
    "title": "CC0 1.0 Universal",
    "section": "",
    "text": "CC0 1.0 Universal\nCREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE LEGAL SERVICES. DISTRIBUTION OF THIS DOCUMENT DOES NOT CREATE AN ATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES THIS INFORMATION ON AN “AS-IS” BASIS. CREATIVE COMMONS MAKES NO WARRANTIES REGARDING THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS PROVIDED HEREUNDER, AND DISCLAIMS LIABILITY FOR DAMAGES RESULTING FROM THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS PROVIDED HEREUNDER.\n\nStatement of Purpose\nThe laws of most jurisdictions throughout the world automatically confer exclusive Copyright and Related Rights (defined below) upon the creator and subsequent owner(s) (each and all, an “owner”) of an original work of authorship and/or a database (each, a “Work”).\nCertain owners wish to permanently relinquish those rights to a Work for the purpose of contributing to a commons of creative, cultural and scientific works (“Commons”) that the public can reliably and without fear of later claims of infringement build upon, modify, incorporate in other works, reuse and redistribute as freely as possible in any form whatsoever and for any purposes, including without limitation commercial purposes. These owners may contribute to the Commons to promote the ideal of a free culture and the further production of creative, cultural and scientific works, or to gain reputation or greater distribution for their Work in part through the use and efforts of others.\nFor these and/or other purposes and motivations, and without any expectation of additional consideration or compensation, the person associating CC0 with a Work (the “Affirmer”), to the extent that he or she is an owner of Copyright and Related Rights in the Work, voluntarily elects to apply CC0 to the Work and publicly distribute the Work under its terms, with knowledge of his or her Copyright and Related Rights in the Work and the meaning and intended legal effect of CC0 on those rights.\n\nCopyright and Related Rights. A Work made available under CC0 may be protected by copyright and related or neighboring rights (“Copyright and Related Rights”). Copyright and Related Rights include, but are not limited to, the following:\n\nthe right to reproduce, adapt, distribute, perform, display, communicate, and translate a Work;\nmoral rights retained by the original author(s) and/or performer(s);\npublicity and privacy rights pertaining to a person’s image or likeness depicted in a Work;\nrights protecting against unfair competition in regards to a Work, subject to the limitations in paragraph 4(a), below;\nrights protecting the extraction, dissemination, use and reuse of data in a Work;\ndatabase rights (such as those arising under Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, and under any national implementation thereof, including any amended or successor version of such directive); and\nother similar, equivalent or corresponding rights throughout the world based on applicable law or treaty, and any national implementations thereof.\n\nWaiver. To the greatest extent permitted by, but not in contravention of, applicable law, Affirmer hereby overtly, fully, permanently, irrevocably and unconditionally waives, abandons, and surrenders all of Affirmer’s Copyright and Related Rights and associated claims and causes of action, whether now known or unknown (including existing as well as future claims and causes of action), in the Work (i) in all territories worldwide, (ii) for the maximum duration provided by applicable law or treaty (including future time extensions), (iii) in any current or future medium and for any number of copies, and (iv) for any purpose whatsoever, including without limitation commercial, advertising or promotional purposes (the “Waiver”). Affirmer makes the Waiver for the benefit of each member of the public at large and to the detriment of Affirmer’s heirs and successors, fully intending that such Waiver shall not be subject to revocation, rescission, cancellation, termination, or any other legal or equitable action to disrupt the quiet enjoyment of the Work by the public as contemplated by Affirmer’s express Statement of Purpose.\nPublic License Fallback. Should any part of the Waiver for any reason be judged legally invalid or ineffective under applicable law, then the Waiver shall be preserved to the maximum extent permitted taking into account Affirmer’s express Statement of Purpose. In addition, to the extent the Waiver is so judged Affirmer hereby grants to each affected person a royalty-free, non transferable, non sublicensable, non exclusive, irrevocable and unconditional license to exercise Affirmer’s Copyright and Related Rights in the Work (i) in all territories worldwide, (ii) for the maximum duration provided by applicable law or treaty (including future time extensions), (iii) in any current or future medium and for any number of copies, and (iv) for any purpose whatsoever, including without limitation commercial, advertising or promotional purposes (the “License”). The License shall be deemed effective as of the date CC0 was applied by Affirmer to the Work. Should any part of the License for any reason be judged legally invalid or ineffective under applicable law, such partial invalidity or ineffectiveness shall not invalidate the remainder of the License, and in such case Affirmer hereby affirms that he or she will not (i) exercise any of his or her remaining Copyright and Related Rights in the Work or (ii) assert any associated claims and causes of action with respect to the Work, in either case contrary to Affirmer’s express Statement of Purpose.\nLimitations and Disclaimers.\n\nNo trademark or patent rights held by Affirmer are waived, abandoned, surrendered, licensed or otherwise affected by this document.\nAffirmer offers the Work as-is and makes no representations or warranties of any kind concerning the Work, express, implied, statutory or otherwise, including without limitation warranties of title, merchantability, fitness for a particular purpose, non infringement, or the absence of latent or other defects, accuracy, or the present or absence of errors, whether or not discoverable, all to the greatest extent permissible under applicable law.\nAffirmer disclaims responsibility for clearing rights of other persons that may apply to the Work or any use thereof, including without limitation any person’s Copyright and Related Rights in the Work. Further, Affirmer disclaims responsibility for obtaining any necessary consents, permissions or other rights required for any use of the Work.\nAffirmer understands and acknowledges that Creative Commons is not a party to this document and has no duty or obligation with respect to this CC0 or use of the Work."
  },
  {
    "objectID": "book/index.html",
    "href": "book/index.html",
    "title": "Contents",
    "section": "",
    "text": "This section contains my notes and exercises as I work through the Statistical Rethinking textbook.\n\n\n\nThe Golem of Prague\nSmall Worlds and Large Worlds",
    "crumbs": [
      "Book Notes",
      "Contents"
    ]
  },
  {
    "objectID": "book/index.html#chapters",
    "href": "book/index.html#chapters",
    "title": "Contents",
    "section": "",
    "text": "The Golem of Prague\nSmall Worlds and Large Worlds",
    "crumbs": [
      "Book Notes",
      "Contents"
    ]
  },
  {
    "objectID": "book/01_the-golem-of-prague.html",
    "href": "book/01_the-golem-of-prague.html",
    "title": "Chapter 1: The Golem of Prague",
    "section": "",
    "text": "Scientistis frequently construct and use “statistical golems” - tools that know their own procedure, but have no inherent wisdom.\n\np-values, stat tests, etc\n\nClassical statistical tools may not be adaptable to all modern research scenarios.\nThe golems are often associative rather than causal, leading to misuse.\n\n\n\n\n\nThe classic approach is to use a “flow-chart” to determine the statistical procedure to use. However, this can lead to battles over picking the “correct” test.\nWe also face epistemological issues, realized as conflation between causation and hypothesis falsification.\n\nKarl Popper’s The Myth of the Framework (1996), his last book, covers this topic.\n\nMcElreath posits that “deductive falsification is impossible”, given that:\n\nHypotheses are not models. So, falsifiying the hypothesis does not falsify the model.\nMeasurement can invalidate models. If the measurement is wrong, falsification is not possible.\nNote that null hypothesis signficance testing (NHST) attempts to falsify the null hypothesis, not the actual research hypothesis.\n\n\n\n\nHypotheses are not models; rather they are one of three pieces that constitute scientific understanding:\n\nHypotheses are falsifiable, often vauge descriptions of evidence.\nProcess models are non-statistical understandings of a mechanisim which supports or refutes a hypothesis.\nStatistical models are statistical understandings of process models.\n\nThese pieces have special properties: - Since hypotheses are vague, they map to multiple process models. - Effectively similarly, statistical models can map to multiple process models. - Therefore, any statistical model can support/refute multiple hypotheses.\nThis conundrum implies that if two models imply similar data, you should search for a description of the data under which the processes look different. Two process models can make similar predictions for field X, but vastly different predictions for Y.\n\n\n\nTwo properties of statistical modeling complicate hypothesis falsification:\n\nObservation error\nContinuous hypotheses\n\n\n\nDifficulty of observation often leads to observed data mapping to multiple hypothetical conclusions. Or, the data can simply be measured incorrectly. Both instances can result in “spurious falsifications,” where the conclusions drawn are due to chance.\n\n\n\nContinuous hypotheses, such as “80% of swans are white” are difficult to prove, since modus tollens (“If P, then Q. Not Q. So, not P.”) does not apply.\n\n\n\n\nIn the scientific community, falsification of hypotheses is not strictly logical; rather, agreements on evidence are reached via consensus. Consequently, claims of science’s definitiveness are usually exaggerated and possibly societally harmful. Kitcher (2011), Science in a Democratic Society, is a good intro to the sociology of science.\n\n\n\n\nScientific research is often broader in scope than testing alone; models fill this gap. In addition to serving testing, models can make predictions and communicate understandings.\nRethinking covers four tools for modeling:\n\nBayesian data analysis\nModel comparison\nMultilevel models\nGraphical causal models\n\n\n\n\nWe just use randomness to describe our uncertainty…\n\nBayseian data analysis is a highly generalizable probability-based tool for using data to learn about the world.\nBayesian analysis is intuitive:\n\nCount* the number of possible explanations.\nIdentify the most plausible explanations based on counts.\n\n*In Bayesian, “count” refers to calculus, since Bayesian is a practice of probability distributions.\nThe frequentist approach, in contrast, imagines an infinte resampling of data to reach a probability distribution. Ironically, however, frequentist tests are often interpreted as Bayesian components (“95% likely that the value falls inside this confidence interval”, e.g).\nFurther, in the frequentist approach, parameters are not random variables. Random variables are useful when the measurement leads to a uniform sampling distribution. In the case of image analysis, bayesian analysis is often used, allowing noisy images to be reconstructed using modeled probabilities.\n\n\n\n\nFitting is easy; prediction is hard.\n\nCross-validation and information criteria are two metrics used to estimate predictive accuracy and evaluate possibility of overfitting:\n\nCross-validation provides provide fit estimates over different resamples of the data.\nInformation criteria are measures that “balance model fit with model complexity”.\n\nRecall that multiple process models can exist for a statistical model. Thus, it is always necessary to compare multiple statistical models for a given problem.\n\n\n\nMultilevel models are hierarchical bayesian models that utilize partial pooling, a statistical technique that uses information across levels of the hierarchy to produce better estimates for units within a level.\nFour common applications of partial pooling:\n\nAdjust for repeat sampling (multiple observations from the same unit)\nAdjust for imbalanced sampling (observation X sampled 10x more than Y)\nStudy variation (useful when question includes variations among a level within the hierarchy)\nAvoid averaging (features are often pre-averaged for traditional models, destorying the data’s variation)\n\nMcElreath argues that “multilevel regression deserves to be the default form of regression,” and that research involving single-level models must justify the decision to not use a multilevel model. Particularly, the researcher must demonstrate lack of variation in treatment effects among observations.\nMultilevel models are not new! From 1960 to 1978 John Tukey developed multilevel models for NBC from that were used for election forecasting.\n\n\n\n\nA statistical model is an amazing assocation engine\n\nFlawed causal models and confounding variables can often lead to better prediction, due to assocation’s predictive power. This often means that scientists can be systematically miseld by predictive accuracy.\nThus, being mindful of the underlying causal assumptions is a mandatory component of statistical modeling. This is most often achieved through construction of a causal model, from which multiple statistical models can be developed.\nGraphical causal models, such as directed acyclic graphs (DAGs), are helpful tools allowing for the visualization of causal relationships. DAGs are developed outside of the data, usually in deep consulation with domain experts.\nToday’s dominating method of causal inference is the causal salad, wherein control variables are carefully tossed into the models, toward the aim of developing a causal narrative. When designing a model to be later used for interventions, it is important that the causal relationships, especially the controlling effects, are explainable.\n\n\n\n\nMcElreath makes the argument that instead of working with a plethora of black-box models, we should aim to develop the skills to analyze null hypotheses. The tools introduced – Bayesian data analysis, model comparison, multilevel modeling, and graphical causal models – serve this aim.\n\n\n\nChapters 2-3: Intro to Bayesian inference\nChapters 4-8: Multiple linear regression\nChapters 9-12: Generalized linear models\nChapters 13-16: Multilevel models\nChapter 17: Address issues from 1st edition\n\nEach chapter ends with exercises across difficulty levels. The more difficult problems introduce new material and challenges.",
    "crumbs": [
      "Book Notes",
      "Chapter 1: The Golem of Prague"
    ]
  },
  {
    "objectID": "book/01_the-golem-of-prague.html#statistical-golems",
    "href": "book/01_the-golem-of-prague.html#statistical-golems",
    "title": "Chapter 1: The Golem of Prague",
    "section": "",
    "text": "Scientistis frequently construct and use “statistical golems” - tools that know their own procedure, but have no inherent wisdom.\n\np-values, stat tests, etc\n\nClassical statistical tools may not be adaptable to all modern research scenarios.\nThe golems are often associative rather than causal, leading to misuse.",
    "crumbs": [
      "Book Notes",
      "Chapter 1: The Golem of Prague"
    ]
  },
  {
    "objectID": "book/01_the-golem-of-prague.html#statistical-rethinking",
    "href": "book/01_the-golem-of-prague.html#statistical-rethinking",
    "title": "Chapter 1: The Golem of Prague",
    "section": "",
    "text": "The classic approach is to use a “flow-chart” to determine the statistical procedure to use. However, this can lead to battles over picking the “correct” test.\nWe also face epistemological issues, realized as conflation between causation and hypothesis falsification.\n\nKarl Popper’s The Myth of the Framework (1996), his last book, covers this topic.\n\nMcElreath posits that “deductive falsification is impossible”, given that:\n\nHypotheses are not models. So, falsifiying the hypothesis does not falsify the model.\nMeasurement can invalidate models. If the measurement is wrong, falsification is not possible.\nNote that null hypothesis signficance testing (NHST) attempts to falsify the null hypothesis, not the actual research hypothesis.\n\n\n\n\nHypotheses are not models; rather they are one of three pieces that constitute scientific understanding:\n\nHypotheses are falsifiable, often vauge descriptions of evidence.\nProcess models are non-statistical understandings of a mechanisim which supports or refutes a hypothesis.\nStatistical models are statistical understandings of process models.\n\nThese pieces have special properties: - Since hypotheses are vague, they map to multiple process models. - Effectively similarly, statistical models can map to multiple process models. - Therefore, any statistical model can support/refute multiple hypotheses.\nThis conundrum implies that if two models imply similar data, you should search for a description of the data under which the processes look different. Two process models can make similar predictions for field X, but vastly different predictions for Y.\n\n\n\nTwo properties of statistical modeling complicate hypothesis falsification:\n\nObservation error\nContinuous hypotheses\n\n\n\nDifficulty of observation often leads to observed data mapping to multiple hypothetical conclusions. Or, the data can simply be measured incorrectly. Both instances can result in “spurious falsifications,” where the conclusions drawn are due to chance.\n\n\n\nContinuous hypotheses, such as “80% of swans are white” are difficult to prove, since modus tollens (“If P, then Q. Not Q. So, not P.”) does not apply.\n\n\n\n\nIn the scientific community, falsification of hypotheses is not strictly logical; rather, agreements on evidence are reached via consensus. Consequently, claims of science’s definitiveness are usually exaggerated and possibly societally harmful. Kitcher (2011), Science in a Democratic Society, is a good intro to the sociology of science.",
    "crumbs": [
      "Book Notes",
      "Chapter 1: The Golem of Prague"
    ]
  },
  {
    "objectID": "book/01_the-golem-of-prague.html#tools-for-golem-engineering",
    "href": "book/01_the-golem-of-prague.html#tools-for-golem-engineering",
    "title": "Chapter 1: The Golem of Prague",
    "section": "",
    "text": "Scientific research is often broader in scope than testing alone; models fill this gap. In addition to serving testing, models can make predictions and communicate understandings.\nRethinking covers four tools for modeling:\n\nBayesian data analysis\nModel comparison\nMultilevel models\nGraphical causal models\n\n\n\n\nWe just use randomness to describe our uncertainty…\n\nBayseian data analysis is a highly generalizable probability-based tool for using data to learn about the world.\nBayesian analysis is intuitive:\n\nCount* the number of possible explanations.\nIdentify the most plausible explanations based on counts.\n\n*In Bayesian, “count” refers to calculus, since Bayesian is a practice of probability distributions.\nThe frequentist approach, in contrast, imagines an infinte resampling of data to reach a probability distribution. Ironically, however, frequentist tests are often interpreted as Bayesian components (“95% likely that the value falls inside this confidence interval”, e.g).\nFurther, in the frequentist approach, parameters are not random variables. Random variables are useful when the measurement leads to a uniform sampling distribution. In the case of image analysis, bayesian analysis is often used, allowing noisy images to be reconstructed using modeled probabilities.\n\n\n\n\nFitting is easy; prediction is hard.\n\nCross-validation and information criteria are two metrics used to estimate predictive accuracy and evaluate possibility of overfitting:\n\nCross-validation provides provide fit estimates over different resamples of the data.\nInformation criteria are measures that “balance model fit with model complexity”.\n\nRecall that multiple process models can exist for a statistical model. Thus, it is always necessary to compare multiple statistical models for a given problem.\n\n\n\nMultilevel models are hierarchical bayesian models that utilize partial pooling, a statistical technique that uses information across levels of the hierarchy to produce better estimates for units within a level.\nFour common applications of partial pooling:\n\nAdjust for repeat sampling (multiple observations from the same unit)\nAdjust for imbalanced sampling (observation X sampled 10x more than Y)\nStudy variation (useful when question includes variations among a level within the hierarchy)\nAvoid averaging (features are often pre-averaged for traditional models, destorying the data’s variation)\n\nMcElreath argues that “multilevel regression deserves to be the default form of regression,” and that research involving single-level models must justify the decision to not use a multilevel model. Particularly, the researcher must demonstrate lack of variation in treatment effects among observations.\nMultilevel models are not new! From 1960 to 1978 John Tukey developed multilevel models for NBC from that were used for election forecasting.\n\n\n\n\nA statistical model is an amazing assocation engine\n\nFlawed causal models and confounding variables can often lead to better prediction, due to assocation’s predictive power. This often means that scientists can be systematically miseld by predictive accuracy.\nThus, being mindful of the underlying causal assumptions is a mandatory component of statistical modeling. This is most often achieved through construction of a causal model, from which multiple statistical models can be developed.\nGraphical causal models, such as directed acyclic graphs (DAGs), are helpful tools allowing for the visualization of causal relationships. DAGs are developed outside of the data, usually in deep consulation with domain experts.\nToday’s dominating method of causal inference is the causal salad, wherein control variables are carefully tossed into the models, toward the aim of developing a causal narrative. When designing a model to be later used for interventions, it is important that the causal relationships, especially the controlling effects, are explainable.",
    "crumbs": [
      "Book Notes",
      "Chapter 1: The Golem of Prague"
    ]
  },
  {
    "objectID": "book/01_the-golem-of-prague.html#summary",
    "href": "book/01_the-golem-of-prague.html#summary",
    "title": "Chapter 1: The Golem of Prague",
    "section": "",
    "text": "McElreath makes the argument that instead of working with a plethora of black-box models, we should aim to develop the skills to analyze null hypotheses. The tools introduced – Bayesian data analysis, model comparison, multilevel modeling, and graphical causal models – serve this aim.\n\n\n\nChapters 2-3: Intro to Bayesian inference\nChapters 4-8: Multiple linear regression\nChapters 9-12: Generalized linear models\nChapters 13-16: Multilevel models\nChapter 17: Address issues from 1st edition\n\nEach chapter ends with exercises across difficulty levels. The more difficult problems introduce new material and challenges.",
    "crumbs": [
      "Book Notes",
      "Chapter 1: The Golem of Prague"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notes on Statistical Rethinking",
    "section": "",
    "text": "This repo contains my notes and code as I work through Richard McElreath’s 2025 course on his book Statistical Rethinking. A course in Bayesian statistics, Rethinking is code-heavy and meant to be read sequentially, not as a reference. McElreath offers his flipped instruction course locally, also publishing the lectures online.\n\n\nThe repoistory is organized into separate quarto files, which are stitched together in _quarto.yml.\n\nbook/: contains notes and exercises directly from the textbook\ncourse/: contains notes from pre-recorded lecutres and slides\nhomework/: contains homework solutions\n\nTo view the site locally, use the command line:\nquarto preview\n\n\n\nThe examples in the book require installation of the {rethinking} R package. Follow these steps to install:\n\nDownload {cmdstanr} from mc-stan.org\nDownload {rethinking}:\n\n# Experiemntal branch contains new tools for 2nd edition\ndevtools::install_github(\"rmcelreath/rethinking\",ref=\"Experimental\")\n\n\n\nThis repository contains my work and solutions for the course Statistical Rethinking (2025 Edition), which is licensed under CC0 1.0 Universal.\nCode examples are adapted from Richard McElreath’s original course materials and/or Statistical Rethinking."
  },
  {
    "objectID": "index.html#organization",
    "href": "index.html#organization",
    "title": "Notes on Statistical Rethinking",
    "section": "",
    "text": "The repoistory is organized into separate quarto files, which are stitched together in _quarto.yml.\n\nbook/: contains notes and exercises directly from the textbook\ncourse/: contains notes from pre-recorded lecutres and slides\nhomework/: contains homework solutions\n\nTo view the site locally, use the command line:\nquarto preview"
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "Notes on Statistical Rethinking",
    "section": "",
    "text": "The examples in the book require installation of the {rethinking} R package. Follow these steps to install:\n\nDownload {cmdstanr} from mc-stan.org\nDownload {rethinking}:\n\n# Experiemntal branch contains new tools for 2nd edition\ndevtools::install_github(\"rmcelreath/rethinking\",ref=\"Experimental\")"
  },
  {
    "objectID": "index.html#attribution",
    "href": "index.html#attribution",
    "title": "Notes on Statistical Rethinking",
    "section": "",
    "text": "This repository contains my work and solutions for the course Statistical Rethinking (2025 Edition), which is licensed under CC0 1.0 Universal.\nCode examples are adapted from Richard McElreath’s original course materials and/or Statistical Rethinking."
  },
  {
    "objectID": "LICENSE-MIT.html",
    "href": "LICENSE-MIT.html",
    "title": "MIT License",
    "section": "",
    "text": "MIT License\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  }
]