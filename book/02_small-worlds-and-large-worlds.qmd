# Chapter 2: Small Worlds and Large Worlds

Statistical modeling exists dualistically, in a **small world** (contained by
the model's inherent logic) and a **big world** (the context in which the model
will live).

In the *small world*, it is important to make sure the model is valid,
consistent, and well-behaved.

The *large world* is the broader context in which the finalized model will
exist. It is important to note that the statistical model *always*
underrepresents the full context of the *large world*. Out of sample data
emerge, and a model's logical inconsistencies can surface.

Adapting to the *large world* is a straightforward process, for nature.
For Bayesian models, the process is much more complex. It is difficult to beat
natural heuristics once a model identifies what to look for.

Chapter 2 focuses on the *small world*.

## 2.1: The garden of forking data

*Bayesian analysis* lends itself to continually exploring alternatives. In this
sense, *Bayesian analysis* creates a series of data "forks" in its quest to
deduce.

## 2.2: Building a model

Development of a Bayesian model is best done cyclically:

1. Create a **data story**
2. Update
3. Evaluate
4. Repeat

### 2.2.1: A data story

The first step is to develop a story, built on either associations or
causality, about the data, particularly its variation. *Data stories* involve
descriptions of the *large world*, as well as the *small world* sampling
process. This story is then put into formal terms of probability.

Recall that any model may map back to multiple stories. Thus, model
success does not necessarily imply confirmation of the story.

### 2.2.2: Bayesian updating

You create a Bayesian model with an initial estimate, your **prior**. Then, as
you sample data, your model learns from the new data, *updating* itself.

### 2.2.3: Evaluate

The nature of Bayesian models guarantees that, within the *small world*, the
model will achieve perfect inference. This means that extra care must be taken
to evaluate the model within the *large world*, where *small world* success
does not necessarily translate.

Remember that a model's assumptions are never 100% correct. Failure to disprove
a model is therefore an error of science, not a sign of success.

## 2.3: Components of the model

### 2.3.1: Variables

In the context of Bayesian models, **variables** refer to either *observable*
**data** or *unobservable* **parameters**.

### 2.3.2: Definitions

The **definitions** of the relationships among *variables* constitute a
**model**.

#### 2.3.2.1: Observed variables

To "count" an **observed variable**, we assign it a probability distribution,
known as a **likelihood**.

#### 2.3.2.2: Unobserved variables

To "count" an **unobserved variable** (a *parameter*), assign it a *prior*,
then *update* the prior as the model learns from the *data*.

The *prior* is part of the model; thus, it should be developed within the same
cyclic development of the rest of the model.

*Priors* are arbitrary, a choice made by the scientist. So, it is important to
test many *priors*. This does not mean that the scientist has undue influence over the model. If the chocsen *prior* is bad, the model will be bad.

## 2.4: Making the model go

Once the components have been established, the Bayesian model will update the
prior distributions until the **posterior distribution** is determined. The
*posterior* contains the probability distribution of different *parameters*,
conditioned on the data and model.

### 2.4.1: Bayes' theorem

Note that the following equations are equivalent:

$$
\Pr(A,B) = \Pr(A|B)\Pr(B) \tag{2.1}
$$

$$
\Pr(A,B) = \Pr(B|A)\Pr(A) \tag{2.2}
$$

Both equations represent the joint probability space of $A$ and $B$.
$(2.1)$ does so by first asking "what is the probability of $B$?" Then, let's
suppose $B$ occurs. Now, $B$ having occurred, "what is the probability of $A$?"
Multiply the two results together. $(2.2)$ follows the same sequence but in
reverse. 

The result is logical equivalence:

$$
\Pr(A|B)\Pr(B) = \Pr(B|A)\Pr(A) \tag{2.3}
$$

Note that this equivalence can also be reached mathematically, via the
definition of conditional probability (in the discrete case) or conditional
density (continuous).

**Bayes' theorem** wonderfully exploits this equivalence:

$$
\Pr(B|A) = \frac{\Pr(A|B)\Pr(B)}{\Pr(A)} \tag{2.4}
$$

Why is the *Bayes' theorem* expression better? The answer lies in practice:

- $\Pr(B|A)$ is difficult to measure directly.
- $\Pr(A|B)$ is the modeled *likelihood*.
- $\Pr(B)$ is simply the *prior*.
- $\Pr(A)$ (see [appendix](#appendix)) is not needed, due to the implied
  proportionality:

$$
\Pr(B|A) \propto \Pr(A|B)\Pr(B) \tag{2.5}
$$

$(2.5)$ says that the *posterior* is proportional to the *likelihood*
multiplied by the *prior*. Since we choose the *prior*, we simply have to
calculate the *likelihood* to find the shape of the *posterior*. We don't need
the exact density values; any needed estimation can be performed on the
proportional density.

While *Bayes' theorem* is used by any probability-based inference,
*Bayesian inference* concerns specifically the generalization of
*Bayes' theorem* to abstractions like *parameters* and *models*.

### 2.4.2: Motors

*Rethinking* introduces three ***motors*** that each approximate
*Bayesian inference*:

1. Grid approximation
2. Quadratic approximation
3. Markov chain Monte Carlo (MCMC)

### 2.4.3: Grid approximation

Similar to grid search in machine learning, **grid approximation** in
*Bayesian inference* achieves great performance in approximating the
*posterior*, using a discrete set of possible *parameter* values.

*Grid approximation* follows 6 steps:

1. Define the *parameter* **grid**:
```{python}
import numpy as np

# change this to increase/decrease approximation precision
N_OUT = 20

p_grid = np.linspace(0, 1, N_OUT)
```

2. Compute the *likelihood* at each *parameter* value:
```{python}
import scipy.stats as st

likelihood = st.binom.pmf(6, 9, p_grid)
```

3. Define the *priors*:
```{python}
priors = [
    np.repeat(1.0, len(p_grid)),  # uninformative prior
    np.where(p_grid < 0.5, 0.0, 1.0),  # 0 if x < 0.5 else 1
    np.exp(-5 * np.abs(p_grid - 0.5)),  # exponential peak centered at 0.5
]
```

4. Compute the *posteriors* by multiplying the *priors* and the *likelihood*:
```{python}
posteriors_unstd = list()
for prior in priors:
    posteriors_unstd.append(likelihood * prior)
```

5. Standardize the *posteriors*:
```{python}
posteriors = list()
for posterior_unstd in posteriors_unstd:
    posteriors.append(posterior_unstd / sum(posterior_unstd))
```

6. Analyze the results. Notice the effect of the prior choice:
```{python}
for posterior in posteriors:
    import matplotlib.pyplot as plt

    # Create the plot
    plt.figure(figsize=(8, 5))
    plt.plot(p_grid, posterior, "-o")

    plt.xlabel("Probability of success")
    plt.ylabel("Posterior probability")
    plt.title("Posterior distribution after 9 draws")

    plt.show()
```

## Appendix

### A2.4.1: Bayes' theorem

Note that $\Pr(A)$ is measurable via the 
[Law of Total Probability](https://en.wikipedia.org/wiki/Law_of_total_probability):

$$
\Pr(A) = \mathbb{E}[\Pr(A|B)] = \int{\Pr(A|B)\Pr(B)dB} \tag{A2.1}
$$

$\mathbb{E}[\Pr(A|B)]$ is also referred to as the **marginal likelihood**.
